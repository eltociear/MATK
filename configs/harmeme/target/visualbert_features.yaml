# lightning.pytorch==2.0.0
seed_everything: 1111
trainer:
  accelerator: gpu
  devices: 1
  max_epochs: 30
  accumulate_grad_batches: 1
  enable_checkpointing: True
  # callbacks: 
  #   - class_path: lightning.pytorch.callbacks.ModelCheckpoint
  #     init_args:
  #       dirpath: checkpoints/visualbert/fhm
  #       monitor: val_auroc
  #       mode: max
  #       save_top_k: 1
  #       every_n_epochs: 1
  #       save_last: True
  #   - class_path: lightning.pytorch.callbacks.EarlyStopping
  #     init_args:
  #       monitor: val_auroc
  #       patience: 5
  #       mode: max
  #   - class_path: models.visualbert.MetricCallback
  #     init_args: 
  #       output_dict: {
  #         "target": 3,
  #         "target": 4
  #       }
model:
  class_path: models.visualbert.VisualBertClassificationModel
  init_args:
    model_class_or_path: uclanlp/visualbert-vqa-coco-pre
    cls_dict: {
      "target": 4
    }
data:
  class_path: datamodules.VLFeaturesDataModule
  init_args:
    tokenizer_class_or_path: bert-base-uncased
    feats_dir: /mnt/sda/datasets/memes/harmemes/features/unc-nlp/frcnn-vg-finetuned/
    annotation_filepaths: {
      train: /mnt/sda/datasets/memes/harmemes/annotations/train.jsonl,
      validate: /mnt/sda/datasets/memes/harmemes/annotations/val.jsonl,
      test: /mnt/sda/datasets/memes/harmemes/annotations/val.jsonl,
      predict: /mnt/sda/datasets/memes/harmemes/annotations/val.jsonl
    }
    shuffle_train: True
    batch_size: 32
    labels:
    - target